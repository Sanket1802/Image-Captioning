{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b65979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from time import time\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50,preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image as im\n",
    "from keras.models import Model,load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input,Dense,Dropout,Embedding,LSTM\n",
    "from keras.layers.merge import add\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c58ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"model_weights/model_9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae8062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp=ResNet50(weights=\"imagenet\",input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cdf142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 35)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 35, 50)       92400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 35, 50)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          524544      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          314368      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_2[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1848)         474936      dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,472,040\n",
      "Trainable params: 1,379,640\n",
      "Non-trainable params: 92,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c50b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet=Model(model_temp.input,model_temp.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f15c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img=im.load_img(img,target_size=(224,224))\n",
    "    img=im.img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)#original image size is(224,224,3) and when we feed it to a model it goes in a certain batch size (b,224,224,3) which is 4d tensor so to convert this image we use expand_dims(img,axis=0) so now image looks like (1,224,224,3), we can also use reshape\n",
    "    #normalization\n",
    "    img= preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8846bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(img):\n",
    "    img=preprocess_img(img)\n",
    "    feature_vector=model_resnet.predict(img)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector=feature_vector.reshape(1,2048)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d2909b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=encode_image(\"1149851.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff951518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d5ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_captions(photo):\n",
    "    max_len=35\n",
    "    in_text=\"startseq\"\n",
    "    for i in range(max_len):\n",
    "        sequence=[word2index[w] for w in in_text.split() if w in word2index]\n",
    "        sequence=pad_sequences([sequence],maxlen=max_len,padding='post')\n",
    "        \n",
    "        ypred=model.predict([photo,sequence])\n",
    "        ypred=ypred.argmax()\n",
    "        word=index2word[ypred]\n",
    "        in_text+=(' '+word)\n",
    "        \n",
    "        if word=='endseq':\n",
    "            break\n",
    "            \n",
    "    final_caption=in_text.split()[1:-1]\n",
    "    final_caption=' '.join(final_caption) \n",
    "    return final_caption\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef5d9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word2index.pkl\",'rb') as w2i:\n",
    "    word2index=pickle.load(w2i)\n",
    "with open(\"index2word.pkl\",'rb') as i2w:\n",
    "    index2word=pickle.load(i2w)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3353672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man in red shirt is holding baby in the air'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_captions(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a2e33",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9decc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16b486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
